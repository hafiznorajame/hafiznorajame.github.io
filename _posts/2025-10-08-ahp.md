---
layout: post
title: "How I use Analytical Hierarchy Process (AHP) to select my MSc dissertation project"
date: 2025-10-08
categories: maths
permalink: /blog/ahp.html
use_math: true
output:
  md_document:
    variant: markdown_github
    preserve_yaml: true
---

AHP is an operations research (OR) tool mainly used in decision making.
The AHP helps decision makers to find an optimal decision that suits
their goals and problems. For those who were wondering, OR is a field of
applied mathematics that applies analytical methods for decision making. The first time I encountered AHP was in early 2024 in my "Advanced Operations Research" module. 

In this post, I aim to show how I use AHP to select my MSc Statistics dissertation topic. This post will not include any theory of AHP here, so there will be no mathematics here! If you are interested in learning more about AHP, you can find more detail about it [here](https://www.researchgate.net/profile/Seyyed-Hossein-Jafari-Petroudi/post/how_do_we_compute_consistency_ratio/attachment/5a345dceb53d2f0bba44affb/AS%3A571976892809216%401513381326103/download/AHP-page13.pdf) (the method is quite simple to understand!). Additional resource include the textbook Operations Research: Applications and Algorithms by Wayne L. Winston. This is my main textbook while studying OR.

## 1) How I used AHP for decision making

Basically, in an AHP, there are three main components: the goal, the criteria, and the alternatives. My goal here is to select a dissertation topic. The criteria are the factors I considered for choosing the dissertation topic, and  the alternatives are simply the potential dissertation topic.

### Alternatives - MSc Statistics disseration topic

For my MSc dissertation, there are about 42 projects offered to MSc
Statistics students. My main goal for the dissertation is to enhance my
statistical theory knowledge and also learn about its application. So, I
was thinking of choosing a project that consists of 80% theory and 20%
application.

My thought process for choosing my potential project was to first remove any
projects that were mostly applied (though I still include an applied project in medical/healthcare). Furthermore, I excluded any projects
 related to time series analysis. While I did well in my time
series module and understand the statistical model and theory, I was not
really interested in exploring it further, and the time series project offered here is related to finance, which is not interesting to me. 

Here are the list
of projects that I was interested in:

| ID  | Title                                               | Research area          |
|---------------|----------------------------------------|------------------|
| **P1**  | Assessing predictive performance of survival models | Survival Analysis      |
| **P2**  | Fitting Markov models                               | Stochastic Processes   |
| **P3**  | Estimation of sparse covariance matrix              | Multivariate Analysis  |
| **P4**  | Joint Modelling of Longitudinal and Survival Data   | Statistics in Medicine |
| **P5**  | The origins of epidemics                            | Epidemiology           |
| **P6**  | Analysis of routine cancer data                     | Statistics in Medicine |

## Criteria

These are the criteria I considered in the AHP:

1.  **Theoretical**: Does the project involve many statistical theory and
    mathematical derivations?

2.  **Knowledge**: How much do I already know about the project's research area?

3.  **Research Area**: How interested am I in the project based on its research area?

4.  **Coding**: How advanced are the R coding skills required for this
    project?

Personally, I would prioritise the research area and the amount of theory in the project. I don't really mind if I have limited prior knowledge in the particular research area. It would also be great if the coding requirements are advanced, but I still prioritise the research area. 

To compare between two different alternatives, we can use the following scale that ranges from equally preferred to extremely preferred, shown as follows:

1. Equally Preferred
2. Equally to Moderately Preferred
3. Moderately Preferred
4. Moderately to Strongly Preferred
5. Strongly Preferred
6. Strongly to Very Strongly Preferred
7. Very Strongly Preferred
8. Very Strongly to Extremely Strongly Preferred
9. Extremely Strongly Preferred

Using the scale above, I can now construct my pairwise comparison matrix for criteria:


|          |  Theoretical |  Knowledge | Research Area | Coding |
|:---------|----------:|----------:|---------:| --------: |
| Theoretical | 1 | 3 | 1/4 | 2 |
| Knowledge | 1/3 | 1 | 1/7 | 2 |
| Research Area | 4 | 7 | 1 | 8 |
| Coding | 1/2 | 1/2 | 1/8 | 1 |

Some interpretations of the table above:
-   For Theoretical, I moderately preferred (number 3) this to Knowledge
    and equally to moderately preferred (number 2) this to Coding.
-   I equally to moderately preferred (number 2) Knowledge to Coding.
-   Research area is the most important criterion, where I moderately to
    strongly preferred (number 4) this to Theoretical, very strongly
    preferred (number 7) this to Knowledge, and very strongly to
    extremely strongly preferred (number 8) this to Coding.



After constructing the comparison matrix, I need to check whether comparison matrix is consistent or not. That is, by calculating the consistency ratio (CR) as follows: 

```r
RI = c(0, 0, 0.58, 0.90, 1.12, 1.24, 1.32) # Ratio index

crit_type = c("Theoretical", "Knowledge", "Research Area", "Coding")
crit = matrix(c(1, 3, 1/4, 2,
                1/3, 1, 1/7, 2,
                4, 7, 1, 8,
                1/2, 1/2, 1/8, 1),
              nrow = 4, ncol = 4, 
              byrow = T, dimnames = list(crit_type, crit_type))
CI_crit = (eigen(A)$values[1]-ncol(crit))/(ncol(crit)-1)
CR_crit = CI_crit/RI[ncol(crit)]
```

```r
> CR_crit
[1] 0.0426974+0i
```
In general, a CR value less than 0.10 indicates that the matrix is consistent. If the CR value is more than 0.10, then I would need to consider revising my pairwise comparison matrix.

## Pairwise comparison matrix for each criterion

### Criterion 1: Theoretical

For Theoretical, I think **P2** will involve lots of probability and statistical theory, whereas **P6** will mostly focus on data analysis and using existing common statistical model. Here is my pairwise comparison matrix for this criterion.

| Project | P1 | P2 | P3 | P4 | P5 | P6 |
|----------|----|----|----|----|----|----|
| **P1** | 1 | 1/6 | 1/3 | 1/4 | 1/4 | 2 |
| **P2** | 6 | 1 | 2 | 4 | 5 | 9 |
| **P3** | 3 | 1/2 | 1 | 2 | 1/3 | 7 |
| **P4** | 4 | 1/4 | 1/2 | 1 | 1/2 | 4 |
| **P5** | 4 | 1/5 | 3 | 2 | 1 | 5 |
| **P6** | 1/2 | 1/9 | 1/7 | 1/4 | 1/5 | 1 |

```r
proj = c("P1", "P2", "P3", "P4", "P5", "P6")
thr = matrix(c(1, 1/6, 1/3, 1/4, 1/4, 2,
               6, 1, 2, 4, 5, 9,
               3, 1/2, 1, 2, 1/3, 7,
               4, 1/4, 1/2, 1, 1/2, 4,
               4, 1/5, 3, 2, 1, 5,
               1/2, 1/9, 1/7, 1/4, 1/5, 1),
            nrow = 6, ncol = 6, 
            byrow = T, dimnames = list(proj, proj))
CI_thr = (eigen(thr)$values[1]-ncol(thr))/(ncol(thr)-1)
CR_thr = CI_thr/RI[ncol(thr)]
```


### Criterion 2: Knowledge


Personally, I think I have more prior knowledge on **P6** since my final year project in my BSc was about analysing cancer data trend. Additionally, I did perform a statistical analysis using the linear mixed model on a cancer data. So that is my reason why I assign a higher scale on **P6**. 

**P5** is about epidemic model, which involves stochastic model. I know a bit about research area but I was not entirely confident whether I fully understand the theory. Hence, why I put a lower scale for this project. Here is my full pairwise comparison matrix for Knowledge.


| Project | P1 | P2 | P3 | P4 | P5 | P6 |
|----------|----|----|----|----|----|----|
| **P1** | 1 | 4 | 4 | 5 | 3 | 1/2 |
| **P2** | 1/4 | 1 | 1/2 | 2 | 3 | 1/3 |
| **P3** | 1/4 | 2 | 1 | 3 | 4 | 1/4 |
| **P4** | 1/5 | 1/2 | 1/3 | 1 | 2 | 1/2 |
| **P5** | 1/3 | 1/3 | 1/4 | 1/2 | 1 | 1/4 |
| **P6** | 2 | 3 | 4 | 2 | 4 | 1 |

```r
knw = matrix(c(1, 4, 4, 5, 3, 1/2,
               1/4, 1, 1/2, 2, 3, 1/3,
               1/4, 2, 1, 3, 4, 1/4,
               1/5, 1/2, 1/3, 1, 2, 1/2,
               1/3, 1/3, 1/4, 1/2, 1, 1/4,
               2, 3, 4, 2, 4, 1),
             nrow = 6, ncol = 6, 
             byrow = T, dimnames = list(proj, proj))
CI_knw = (eigen(knw)$values[1]-ncol(knw))/(ncol(knw)-1)
CR_knw = CI_knw/RI[ncol(knw)]
```


### Criterion 3: Research Area

One of my interests in statistics is to build and understand statistical models that are robust to irregularities such as non-linearity and non-normality. Additionally, I am interested in medical statistics. So that's the reason why I put a higher weight for **P4**. Here is my pairwise comparison matrix:

| Project | P1 | P2 | P3 | P4 | P5 | P6 |
|----------|----|----|----|----|----|----|
| **P1** | 1 | 4 | 2 | 1/2 | 3 | 4 |
| **P2** | 1/4 | 1 | 1 | 1/5 | 2 | 1/3 |
| **P3** | 1/2 | 1 | 1 | 1/2 | 2 | 1/2 |
| **P4** | 2 | 5 | 2 | 1 | 5 | 2 |
| **P5** | 1/3 | 1/2 | 1/2 | 1/5 | 1 | 1/3 |
| **P6** | 1/4 | 3 | 2 | 1/2 | 3 | 1 |

```r
rsc = matrix(c(1, 4, 2, 1/2, 3, 4,
               1/4, 1, 1, 1/5, 2, 1/3,
               1/2, 1, 1, 1/2, 2, 1/2,
               2, 5, 2, 1, 5, 2,
               1/3, 1/2, 1/2, 1/5, 1, 1/3,
               1/4, 3, 2, 1/2, 3, 1),
           nrow = 6, ncol = 6, 
           byrow = T, dimnames = list(proj, proj))
CI_rsc = (eigen(rsc)$values[1]-ncol(rsc))/(ncol(rsc)-1)
CR_rsc = CI_rsc/RI[ncol(rsc)]
```

### Criterion 4: Coding

From the dissertation description, I think **P2** will involves lots of coding for simulation. Hence why I put a higher scale for this project. For *P6*, since it is about analysing cancer data, I think this will be the least challenging in terms of coding. Here is my pairwise comparison matrix:


| Project | P1 | P2 | P3 | P4 | P5 | P6 |
|----------|----|----|----|----|----|----|
| **P1** | 1 | 1/4 | 2 | 1/3 | 1/2 | 4 |
| **P2** | 4 | 1 | 3 | 3 | 3 | 4 |
| **P3** | 1/2 | 1/3 | 1 | 1/2 | 2 | 3 |
| **P4** | 3 | 1/3 | 2 | 1 | 4 | 6 |
| **P5** | 2 | 1/3 | 1/2 | 1/4 | 1 | 4 |
| **P6** | 1/4 | 1/4 | 1/3 | 1/6 | 1/4 | 1 |

```r
coding = matrix(c(1, 1/4, 2, 1/3, 1/2, 4,
                  4, 1, 3, 3, 3, 4,
                  1/2, 1/3, 1, 1/2, 2, 3,
                  3, 1/3, 2, 1, 4, 6,
                  2, 1/3, 1/2, 1/4, 1, 4,
                  1/4, 1/4, 1/3, 1/6, 1/4, 1),
                nrow = 6, ncol = 6,
                byrow = T, dimnames = list(proj, proj))
CI_coding = (eigen(coding)$values[1]-ncol(coding))/(ncol(coding)-1)
CR_coding = CI_coding/RI[ncol(coding)]
```

All of the pairwise comparisons matrix for each criterion is consistent.

```r
> CR_thr
[1] 0.07288381+0i
> CR_knw
[1] 0.09399024+0i
> CR_rsc
[1] 0.05561777+0i
> CR_coding
[1] 0.09450809+0i
```
Now, I can proceed to AHP.

## Decision making

In `R`, we can use the function `AHP()` from the package `MCDA` to perform AHP (refer [here](https://www.rdocumentation.org/packages/MCDA/versions/0.1.0/topics/AHP)).

```r
library(MCDA)
alt = list(thr = thr,
           knw = knw,
           rsc = rsc,
           coding = coding)
AHP(crit, alt)
```

The output of the code above:

```r
> AHP(crit, alt)
       P1        P2        P3        P4        P5        P6 
0.2241615 0.1679770 0.1209295 0.2563055 0.0891035 0.1415229 
```

Based on the output above, **P4** (Joint model) has the highest weighted value ($w_{p4}=0.256$), followed by **P1**  and **P2**. **P5** has the lowest weighted value. So this is my ranking of selected projects after performing AHP:

| Rank | ID  | Title                                               | Weighted value          |
|---------------|----------------------------------------|------------------|
| 1 |P4  | Joint Modelling of Longitudinal and Survival Data   | 0.256 |
| 2 |P1  | Assessing predictive performance of survival models | 0.224      |
| 3 |P2  | Fitting Markov models                               | 0.168   |
| 4 | P6  | Analysis of routine cancer data                     | 0.142 |
| 5 | P3  | Estimation of sparse covariance matrix              | 0.121  |
| 6 | P5  | The origins of epidemics                            | 0.089   |

Eventually, **P4** is my dissertation project and I think I made the right decision of choosing this as my first pick. A bit of summary about my dissertation:

- Joint model is a statistical model for joint analysis of longitudinal data and survival data in a single framework. It is more commonly used in many medical research, though there's an increasing use in other field such as social science.
- I used Bayesian inference for parameter estimation. Some of the tasks include deriving the conditional distributions for each parameter. (Note that the joint model is a very complex model, so deriving the distributions are mathematically challenging). The main reason why I need to do this is to code these mathematical expression into my R code for estimating the model parameter. Additionally, I also used Markov Chain Monte Carlo for sampling.
- Changing the normality assumption into t-distributed error and learning what prior distribution used in a t-model.
- *More on coding side*, I learned how to code in `C++` via the package `Rcpp` (I am still not proficient in it).
- Gain some knowledge on Alzheimer's Disease.

I might post more about Joint Model in the future.

## 2) My remarks on AHP

Here are my remarks on performing AHP, based on my previous analysis:
1. The comparison matrix is purely subjective - that is it relies heavily on the decision maker's perceptions and preferences.
2. Repetitive evaluations - when dealing with many criteria or alternatives, the number of pairwise comparisons increases. Additionally, revising the matrix to improve consistency ratio can be tedious.
3. Sensitivity to changes in the matrix - small changes in pairwise comparisons can sometimes lead to large changes in the final ranking.

Nonetheless, AHP can be still useful in some cases for decision making, particularly when the problem size is manageable.
